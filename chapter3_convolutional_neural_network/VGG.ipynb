{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  使用重复元素的网络（VGG）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG块的组成规律是：连续使用数个相同的填充为1、窗口形状为3 \\* 3的卷积层后,接上一个步幅为2 、窗口形状为2 * 2 的最大池化层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon,nd,init\n",
    "from mxnet.gluon import nn,data as gdata,loss as gloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gluonbook as gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs,num_channels):\n",
    "    blk = nn.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        blk.add(nn.Conv2D(num_channels,kernel_size=3,padding=1,activation='relu')\n",
    "        )\n",
    "    #卷积层之后加入\n",
    "    blk.add(nn.MaxPool2D(pool_size=2,strides=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通AlexNet和LeNet一样，VGG网络由卷积层模块后接全连接层模块构成。卷积层模块串联数个vgg_block，其超参数由变量 conv_arch 定义。该变量指定了每个 VGG 块⾥卷积层个数和输出通道数。全连接模块则跟 AlexNet 中的⼀样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们构造⼀个 VGG ⽹络。它有 5 个卷积块，前两块使⽤单卷积层，而后三块使⽤双卷积层。\n",
    "第⼀块的输出通道是 64，之后每次对输出通道数翻倍，直到变为 512。因为这个⽹络使⽤了 8 个\n",
    "卷积层和 3 个全连接层，所以经常被称为 VGG-11。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1,64),(1,128),(2,256),(2,512),(2,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    VGG = nn.Sequential()\n",
    "    #卷积层部分\n",
    "    for num_convs,num_channels in conv_arch:\n",
    "        VGG.add(vgg_block(num_convs,num_channels))\n",
    "    #全连接层部分\n",
    "    VGG.add(nn.Dense(128,activation='relu'),nn.Dropout(0.5),\n",
    "            nn.Dense(128,activation='relu'),nn.Dropout(0.5),\n",
    "            nn.Dense(10))\n",
    "    return VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential1 output shape (1, 64, 112, 112)\n",
      "sequential2 output shape (1, 128, 56, 56)\n",
      "sequential3 output shape (1, 256, 28, 28)\n",
      "sequential4 output shape (1, 512, 14, 14)\n",
      "sequential5 output shape (1, 512, 7, 7)\n",
      "dense0 output shape (1, 128)\n",
      "dropout0 output shape (1, 128)\n",
      "dense1 output shape (1, 128)\n",
      "dropout1 output shape (1, 128)\n",
      "dense2 output shape (1, 10)\n"
     ]
    }
   ],
   "source": [
    "VGG.initialize(ctx=mx.gpu())\n",
    "\n",
    "X =nd.random.uniform(shape=(1,1,224,224),ctx=mx.gpu())\n",
    "\n",
    "for layer in VGG:\n",
    "    X = layer(X)\n",
    "    print(layer.name,'output shape',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 16\n",
    "\n",
    "small_conv_arch = [(pair[0],pair[1] // ratio) for pair in conv_arch]\n",
    "small_VGG = vgg(small_conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size, ctx = 0.05, 5, 128, gb.try_gpu()\n",
    "small_VGG.initialize(ctx=ctx, init=init.Xavier(),force_reinit=True)\n",
    "trainer = gluon.Trainer(small_VGG.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "\n",
    "def load_data_fashion_mnist(batch_size,resize=None):\n",
    "    transformer = []\n",
    "    path = '../chapter1_baseKnowledge/FashionMNIST/'\n",
    "    if resize:\n",
    "        transformer += [gdata.vision.transforms.Resize(resize)]\n",
    "    transformer += [gdata.vision.transforms.ToTensor()]\n",
    "    transformer = gdata.vision.transforms.Compose(transformer)\n",
    "    mnist_train =gdata.vision.FashionMNIST(root=path,train=True)\n",
    "    mnist_test =gdata.vision.FashionMNIST(root= path,train=False)\n",
    "    \n",
    "    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),batch_size,shuffle = True)\n",
    "    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),batch_size,shuffle=False)\n",
    "    \n",
    "    return train_iter,test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n",
      "epoch 1, loss 1.1843, train acc 0.545, test acc 0.785, time 92.5 sec\n",
      "epoch 2, loss 0.6306, train acc 0.767, test acc 0.842, time 88.1 sec\n",
      "epoch 3, loss 0.5161, train acc 0.817, test acc 0.871, time 88.2 sec\n",
      "epoch 4, loss 0.4532, train acc 0.840, test acc 0.876, time 88.0 sec\n",
      "epoch 5, loss 0.4142, train acc 0.856, test acc 0.876, time 88.1 sec\n"
     ]
    }
   ],
   "source": [
    "train_iter,test_iter = load_data_fashion_mnist(batch_size =batch_size,resize=224)\n",
    "\n",
    "gb.train_ch5(small_VGG, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
