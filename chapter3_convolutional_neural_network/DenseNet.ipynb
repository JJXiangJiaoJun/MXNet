{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DensNet\n",
    "### DenseNet借鉴了ResNet的思想，唯一的不同在于，ResNet中连接是将输入和输出相加，而DenseNet则是在通道上进行连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * DenseNet中的单元叫做稠密块，它采用了额ResNet中的改良版本 'BN + 激活函数 + 卷积'结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import gluonbook as gb\n",
    "from mxnet import gluon, init, nd\n",
    "from mxnet.gluon import nn\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(num_channels):\n",
    "    blk = nn.Sequential()\n",
    "    blk.add(nn.BatchNorm(),nn.Activation('relu'),nn.Conv2D(num_channels,kernel_size=3,padding=1))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 稠密块由多个 conv_block组成，每块使用相同的输出通道数。前向计算式，我们将每块的输入和输出在通道维上连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Block):\n",
    "    def __init__(self,num_convs,num_channels,**kwargs):\n",
    "        super(DenseBlock,self).__init__(**kwargs)\n",
    "        self.net = nn.Sequential()    \n",
    "        for _ in range(num_convs):\n",
    "            self.net.add(conv_block(num_channels))\n",
    "            \n",
    "    def forward(self,X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            X = nd.concat(X,Y,dim=1) #在通道维上进行输出连接\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 23, 8, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = DenseBlock(2,10)\n",
    "blk.initialize(ctx=mx.gpu(),force_reinit=True)\n",
    "X =nd.random.uniform(shape=(4,3,8,8),ctx=mx.gpu())\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过渡层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 由于每个稠密块都会带来通道数的增加，使用过多则会带来过于复杂的模型。过渡层用来控制模型的复杂度。它通过1\\*1卷积层来减小通道数，并且使用步幅为2的平均池化层来减半高和宽，从而进一步降低模型复杂度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(num_channels):\n",
    "    blk = nn.Sequential()\n",
    "    blk.add(nn.BatchNorm(),nn.Activation('relu'),\n",
    "            nn.Conv2D(num_channels,kernel_size=1),\n",
    "            nn.MaxPool2D(pool_size=2,strides=2)\n",
    "            )\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10, 4, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = transition_block(10)\n",
    "blk.initialize(ctx= mx.gpu())\n",
    "blk(Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DenseNet = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DenseNet.add(\n",
    "             nn.Conv2D(channels=32,kernel_size=7,strides=2,padding=3),\n",
    "             nn.BatchNorm(),nn.Activation('relu'),\n",
    "             nn.MaxPool2D(pool_size=3,strides=2,padding=1)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 接下来使用四个稠密块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels,growth_rate = 32,16\n",
    "num_convs_in_dense_blocks = [2,2,2,2]\n",
    "\n",
    "for i,num_convs in enumerate(num_convs_in_dense_blocks):\n",
    "    DenseNet.add(DenseBlock(num_convs,growth_rate))\n",
    "    \n",
    "    #上一个稠密通道的输出通道数\n",
    "    num_channels += num_convs*growth_rate  #每个稠密块将增加2*16=32个通道数\n",
    "    \n",
    "    if i!=len(num_convs_in_dense_blocks)-1:\n",
    "        DenseNet.add(transition_block(num_channels//2))  #将通道减半，降低模型复杂度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DenseNet.add(nn.BatchNorm(),nn.Activation('relu'),nn.GlobalAvgPool2D(),nn.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n",
      "epoch 1, loss 0.4823, train acc 0.834, test acc 0.887, time 42.1 sec\n",
      "epoch 2, loss 0.3015, train acc 0.890, test acc 0.881, time 40.0 sec\n",
      "epoch 3, loss 0.2609, train acc 0.906, test acc 0.888, time 39.8 sec\n",
      "epoch 4, loss 0.2370, train acc 0.914, test acc 0.918, time 40.3 sec\n",
      "epoch 5, loss 0.2166, train acc 0.921, test acc 0.877, time 39.5 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs, batch_size, ctx = 0.1,10, 64, gb.try_gpu()\n",
    "DenseNet.initialize(ctx=ctx, init=init.Xavier(),force_reinit=True)\n",
    "trainer = gluon.Trainer(DenseNet.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "train_iter, test_iter = gb.load_data_fashion_mnist(batch_size, resize=96)\n",
    "gb.train_ch5(DenseNet, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批量数较小时，相对来说训练速度会变慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n",
      "epoch 1, loss 0.3164, train acc 0.886, test acc 0.897, time 41.3 sec\n",
      "epoch 2, loss 0.2403, train acc 0.911, test acc 0.914, time 42.8 sec\n",
      "epoch 3, loss 0.2161, train acc 0.922, test acc 0.886, time 40.1 sec\n",
      "epoch 4, loss 0.1981, train acc 0.929, test acc 0.907, time 42.6 sec\n",
      "epoch 5, loss 0.1837, train acc 0.933, test acc 0.915, time 39.5 sec\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "gb.train_ch5(DenseNet, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
