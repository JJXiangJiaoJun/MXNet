{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogLeNet中的基础卷积块叫 Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import gluonbook as gb\n",
    "from mxnet import gluon, init, nd\n",
    "from mxnet.gluon import nn,data as gdata\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Block):\n",
    "    #c1,c2,c3,c4为每个路线输出的通道个数\n",
    "    def __init__(self,c1,c2,c3,c4,**kwargs):\n",
    "        super(Inception,self).__init__(**kwargs)\n",
    "        self.p1_1 = nn.Conv2D(c1,kernel_size=1,activation='relu')\n",
    "        self.p2_1 = nn.Conv2D(c2[0],kernel_size=1,activation='relu')\n",
    "        self.p2_2 = nn.Conv2D(c2[1],kernel_size=3,padding=1,activation='relu')\n",
    "        self.p3_1 = nn.Conv2D(c3[0],kernel_size=1,activation='relu')\n",
    "        self.p3_2 = nn.Conv2D(c3[1],kernel_size=5,padding=2,activation='relu')\n",
    "        self.p4_1 = nn.MaxPool2D(pool_size=3,padding=1,strides=1)\n",
    "        self.p4_2 = nn.Conv2D(c4,kernel_size=1,activation='relu')\n",
    "    def forward(self,X):\n",
    "        p1 = self.p1_1(X)\n",
    "        p2 = self.p2_2(self.p2_1(X))\n",
    "        p3 = self.p3_2(self.p3_1(X))\n",
    "        p4 = self.p4_2(self.p4_1(X))\n",
    "        \n",
    "        #最后所有将结果在输出通道上连接\n",
    "        return nd.concat(p1,p2,p3,p4,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = Inception(10,(5,10),(5,10),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 40, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "X = nd.random.uniform(shape =(1,1,96,96),ctx=mx.gpu())\n",
    "inception.initialize(ctx=mx.gpu(),force_reinit=True)\n",
    "print(inception(X).shape) #输出为四个通道结构相加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主体卷积部分使用了五个模块，每个模块之间使用步幅为2的3 x 3 最大池化层来减小输出高宽"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 第一个模块使用了64通道的7 * 7 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential()\n",
    "b1.add(nn.Conv2D(channels=64,kernel_size=7,strides=2,padding=3,activation='relu'),\n",
    "       nn.MaxPool2D(pool_size=3,strides=2,padding=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 第二个模块使用了两个卷积层：首先是64通道的1 x 1卷积层，然后是将通道增大3倍的3x3卷积层。它对应Inception块中的第二条线路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 =nn.Sequential()\n",
    "b2.add(nn.Conv2D(channels=64,kernel_size=1,activation='relu'),\n",
    "       nn.Conv2D(channels=192,kernel_size=3,padding=1),\n",
    "       nn.MaxPool2D(pool_size=3,strides=2,padding=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 第三个模块串联两个完整的Inception块。第一个Inception块的输出通道数为256，其中四个线路的输出通道比例为2:4:1:1,。且第二、三线路分别将输入通减小2倍和12倍后再进入第二层卷积层。第⼆个 Inception 块输出通道数增⾄ 480，每个线路的通道⽐例为 4:6:3:2。且第⼆、三线路先分别减少 2 倍和 8 倍通道数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3 = nn.Sequential()\n",
    "b3.add(Inception(64,(96,128),(16,32),32),\n",
    "       Inception(128,(128,192),(32,96),64),\n",
    "       nn.MaxPool2D(pool_size=3,strides=2,padding=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 第四模块更加复杂。它串联了五个 Inception 块，其输出通道数分别是 192 + 208 + 48 + 64 =512、 160 + 224 + 64 + 64 = 512、 128 + 256 + 64 + 64 = 512、 112 + 288 + 64 + 64 = 528 和256 + 320 + 128 + 128 = 832。这些线路的通道数分配和第三模块中的类似：含 3 × 3 卷积层的第⼆条线路输出最多通道，其次是仅含 1 × 1 卷积层的第⼀条线路，之后是含 5 × 5 卷积层的第三条线路和含 3 × 3 最⼤池化层的第四条线路。其中第⼆、第三条线路都会先按⽐例减小通道数。这些⽐例在各个 Inception 块中都略有不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4 = nn.Sequential()\n",
    "b4.add(Inception(192, (96, 208), (16, 48), 64),\n",
    "Inception(160, (112, 224), (24, 64), 64),\n",
    "Inception(128, (128, 256), (24, 64), 64),\n",
    "Inception(112, (144, 288), (32, 64), 64),\n",
    "Inception(256, (160, 320), (32, 128), 128),\n",
    "nn.MaxPool2D(pool_size=3, strides=2, padding=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 第五模块有输出通道数为 256 + 320 + 128 + 128 = 832 和 384 + 384 + 128 + 128 = 1024 的两个Inception 块。其中每条线路的通道数分配思路和第三、第四模块中的⼀致，只是在具体数值上有所不同。需要注意的是，第五模块的后⾯紧跟输出层，该模块同 NiN ⼀样使⽤全局平均池化层来将每个通道的⾼和宽变成 1。最后我们将输出变成⼆维数组后接上⼀个输出个数为标签类数的全连接层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5 = nn.Sequential()\n",
    "b5.add(Inception(256, (160, 320), (32, 128), 128),\n",
    "       Inception(384, (192, 384), (48, 128), 128),\n",
    "        nn.GlobalMaxPool2D(),\n",
    "        )\n",
    "\n",
    "GoogLeNet = nn.Sequential()\n",
    "GoogLeNet.add(b1,b2,b3,b4,b5,nn.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential0 output shape:\t (1, 64, 24, 24)\n",
      "sequential1 output shape:\t (1, 192, 12, 12)\n",
      "sequential2 output shape:\t (1, 480, 6, 6)\n",
      "sequential3 output shape:\t (1, 832, 3, 3)\n",
      "sequential4 output shape:\t (1, 1024, 1, 1)\n",
      "dense0 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    " X = nd.random.uniform(shape=(1, 1, 96, 96),ctx=mx.gpu())\n",
    "GoogLeNet.initialize(ctx=mx.gpu())\n",
    "for layer in GoogLeNet:\n",
    "    X = layer(X)\n",
    "    print(layer.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size,resize=None):\n",
    "    transformer = []\n",
    "    path = '../chapter1_baseKnowledge/FashionMNIST/'\n",
    "    if resize:\n",
    "        transformer += [gdata.vision.transforms.Resize(resize)]\n",
    "    transformer += [gdata.vision.transforms.ToTensor()]\n",
    "    transformer = gdata.vision.transforms.Compose(transformer)\n",
    "    mnist_train =gdata.vision.FashionMNIST(root=path,train=True)\n",
    "    mnist_test =gdata.vision.FashionMNIST(root= path,train=False)\n",
    "    \n",
    "    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),batch_size,shuffle = True)\n",
    "    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),batch_size,shuffle=False)\n",
    "    \n",
    "    return train_iter,test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size, ctx = 0.1, 5, 32, gb.try_gpu()\n",
    "GoogLeNet.initialize(force_reinit=True,init=init.Xavier(),ctx=ctx)\n",
    "train_iter,test_iter = load_data_fashion_mnist(batch_size =batch_size,resize=224)\n",
    "trainer = gluon.Trainer(GoogLeNet.collect_params(), 'sgd', {'learning_rate': lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "[21:50:43] c:\\jenkins\\workspace\\mxnet\\mxnet\\src\\operator\\nn\\./cudnn/cudnn_convolution-inl.h:663: Check failed: e == CUDNN_STATUS_SUCCESS (2 vs. 0) cuDNN: CUDNN_STATUS_ALLOC_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a69b917dc191>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_ch5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGoogLeNet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\GitHub\\MXNet\\gluonbook\\utils.py\u001b[0m in \u001b[0;36mtrain_ch5\u001b[1;34m(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m             \u001b[0mtrain_l_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m             \u001b[0mtrain_acc_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mxnet\\ndarray\\ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The current array is not a scalar\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mxnet\\ndarray\\ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1978\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1979\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1980\u001b[1;33m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[0;32m   1981\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mxnet\\base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \"\"\"\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMXNetError\u001b[0m: [21:50:43] c:\\jenkins\\workspace\\mxnet\\mxnet\\src\\operator\\nn\\./cudnn/cudnn_convolution-inl.h:663: Check failed: e == CUDNN_STATUS_SUCCESS (2 vs. 0) cuDNN: CUDNN_STATUS_ALLOC_FAILED"
     ]
    }
   ],
   "source": [
    "gb.train_ch5(GoogLeNet,train_iter,test_iter,batch_size,trainer,ctx,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
