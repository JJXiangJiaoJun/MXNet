{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd,autograd,nd,init,contrib,gluon\n",
    "from mxnet.gluon import nn,data as gdata,loss as gloss\n",
    "import gluonbook as gb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_predictor(num_anchors,num_classes):\n",
    "    return nn.Conv2D(channels=num_anchors*(num_classes+1),kernel_size=3,padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_predictor(num_anchors):\n",
    "    return nn.Conv2D(channels=num_anchors*4,kernel_size=3,padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample_blk(num_channels):\n",
    "    blk = nn.Sequential()\n",
    "    blk.add(nn.BatchNorm(),nn.Activation('relu'),\n",
    "           nn.Conv2D(channels=num_channels//2,kernel_size=1,strides=1),\n",
    "            nn.BatchNorm(),nn.Activation('relu'),\n",
    "           nn.Conv2D(channels=num_channels,kernel_size=3,strides=1,padding=1))\n",
    "    \n",
    "    blk.add(nn.MaxPool2D(pool_size=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_forward(net):\n",
    "    X = nd.uniform(shape=(1,3,256,256),ctx=mx.gpu())\n",
    "    print('original shape =',X.shape)\n",
    "    net.initialize(ctx=mx.gpu())\n",
    "    print('ouput shape =',net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape = (1, 3, 256, 256)\n",
      "ouput shape = \n",
      "[[[[ 0.00630182 -0.00287076  0.00978196 ...  0.01074085 -0.00739565\n",
      "     0.00426991]\n",
      "   [ 0.03914755  0.03505199  0.0104829  ...  0.01344586  0.02638256\n",
      "     0.00646955]\n",
      "   [-0.00102503  0.01640964  0.00349047 ...  0.0041425   0.01326667\n",
      "     0.00690887]\n",
      "   ...\n",
      "   [ 0.00793571  0.00656327  0.02307148 ... -0.00805367  0.00988335\n",
      "     0.00761725]\n",
      "   [-0.00037713  0.02453185 -0.00191945 ...  0.02554989  0.02533143\n",
      "     0.01285604]\n",
      "   [ 0.00565997  0.0209941   0.02889473 ...  0.0109336   0.01575508\n",
      "     0.02148684]]\n",
      "\n",
      "  [[ 0.02334058  0.02347069  0.02158521 ...  0.03161862  0.02083528\n",
      "     0.02181804]\n",
      "   [ 0.02808554  0.0289668   0.01944274 ...  0.0201186   0.03380858\n",
      "     0.02204946]\n",
      "   [ 0.02078616  0.01712939  0.01900282 ...  0.0360853   0.01502372\n",
      "     0.02443051]\n",
      "   ...\n",
      "   [ 0.02227004  0.02596958  0.01991541 ...  0.03325571  0.02531973\n",
      "     0.02893921]\n",
      "   [ 0.01430886  0.03260048  0.0250055  ...  0.02686636  0.02567566\n",
      "     0.02485057]\n",
      "   [ 0.0394523   0.01337383  0.02940251 ...  0.03449968  0.02877176\n",
      "     0.02534208]]\n",
      "\n",
      "  [[ 0.01294652  0.0028153   0.01222479 ... -0.00499317 -0.00289555\n",
      "     0.0032165 ]\n",
      "   [-0.00884094  0.00377286  0.00379991 ... -0.00020996 -0.01204876\n",
      "    -0.01629668]\n",
      "   [ 0.00152597 -0.0055462   0.00466297 ...  0.01260613 -0.00737508\n",
      "    -0.00926065]\n",
      "   ...\n",
      "   [-0.00288214  0.00076323 -0.0019786  ... -0.01244062 -0.00630601\n",
      "    -0.00601064]\n",
      "   [-0.00144141 -0.00692206 -0.0014904  ... -0.00275792 -0.02363569\n",
      "    -0.00791536]\n",
      "   [ 0.00206091 -0.00361033 -0.00311862 ...  0.00327348 -0.01107432\n",
      "     0.01149299]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.03810438  0.012166    0.02857403 ...  0.0157811   0.00774765\n",
      "     0.0165936 ]\n",
      "   [ 0.0368548   0.0287923   0.03415009 ...  0.016054    0.03512046\n",
      "     0.01937179]\n",
      "   [ 0.0233277   0.02590535  0.01547716 ...  0.01329362  0.02810761\n",
      "     0.02645155]\n",
      "   ...\n",
      "   [ 0.0134177   0.01780059  0.01897955 ...  0.03006084  0.01542147\n",
      "     0.01069111]\n",
      "   [ 0.00468097  0.01587776  0.01704229 ...  0.02077452  0.04638105\n",
      "     0.03001919]\n",
      "   [ 0.0254456   0.01743457  0.02651493 ...  0.03287805  0.01398276\n",
      "     0.02845841]]\n",
      "\n",
      "  [[ 0.01863492  0.00054804  0.01364423 ...  0.00177785  0.0130033\n",
      "    -0.00325795]\n",
      "   [ 0.0205874   0.02377004  0.01462125 ...  0.02730835  0.01332766\n",
      "     0.00524304]\n",
      "   [ 0.02017298  0.01357423  0.0119824  ...  0.02103325  0.01742054\n",
      "     0.01476046]\n",
      "   ...\n",
      "   [ 0.01829517  0.01732847  0.03014281 ...  0.01862533  0.01814539\n",
      "     0.02490926]\n",
      "   [ 0.00603459  0.01540106  0.01340628 ...  0.01790536  0.03094332\n",
      "     0.01103894]\n",
      "   [ 0.02702677  0.01503681  0.01478869 ...  0.0298827   0.01608967\n",
      "     0.01548134]]\n",
      "\n",
      "  [[ 0.03902167  0.02195581  0.03370134 ...  0.03978713  0.04189269\n",
      "     0.03712057]\n",
      "   [ 0.06249415  0.05999427  0.04887353 ...  0.05132607  0.05702295\n",
      "     0.04655591]\n",
      "   [ 0.05020795  0.05907936  0.05475777 ...  0.05223708  0.05130999\n",
      "     0.04813606]\n",
      "   ...\n",
      "   [ 0.02930622  0.04639639  0.04905552 ...  0.04505454  0.04975037\n",
      "     0.05253516]\n",
      "   [ 0.03687188  0.04414667  0.05652157 ...  0.0523822   0.0570811\n",
      "     0.06605247]\n",
      "   [ 0.0485148   0.05654988  0.05808846 ...  0.06722695  0.06954431\n",
      "     0.05713105]]]]\n",
      "<NDArray 1x128x128x128 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "go_forward(down_sample_blk(128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下面定义基础网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_blk(num_channels):\n",
    "    blk = nn.Sequential()\n",
    "    for _ in range(2):\n",
    "        blk.add(nn.BatchNorm(),\n",
    "                nn.Activation('relu'),\n",
    "                nn.Conv2D(channels=num_channels,kernel_size=3,strides=1,padding=1))\n",
    "    blk.add(nn.BatchNorm(),nn.Activation('relu'),\n",
    "            nn.Conv2D(channels=num_channels,kernel_size=1,strides=1))\n",
    "    blk.add(nn.MaxPool2D(pool_size=2,strides=2))\n",
    "    \n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_16():\n",
    "    vgg_16 = nn.Sequential()\n",
    "    conv = (32,64,128,256,512,512)\n",
    "    vgg_16.add(nn.BatchNorm(),nn.Activation('relu'),\n",
    "              nn.Conv2D(channels=conv[0],kernel_size=7,strides=1,padding=3),\n",
    "              nn.BatchNorm(),nn.Activation('relu'),\n",
    "              nn.Conv2D(channels=conv[0],kernel_size=3,strides=1,padding=1))   \n",
    "    #vgg_16.add(nn.MaxPool2D(pool_size=2,strides=2))    \n",
    "    for i in range(3):\n",
    "        vgg_16.add(vgg_blk(conv[i+1]))\n",
    "    \n",
    "    #最后两层换成卷积\n",
    "    vgg_16.add(nn.BatchNorm(),nn.Activation('relu'),\n",
    "               nn.Conv2D(channels=conv[4],kernel_size=3,strides=1,padding=1),\n",
    "               nn.BatchNorm(),nn.Activation('relu'),\n",
    "               nn.Conv2D(channels=conv[5],kernel_size=1))\n",
    "    \n",
    "    return vgg_16\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape = (1, 3, 256, 256)\n",
      "ouput shape = \n",
      "[[[[-2.75644776e-03 -2.35306984e-03 -2.24168017e-03 ... -2.56139808e-03\n",
      "    -2.81981169e-03 -1.22101826e-03]\n",
      "   [-5.48647530e-03 -5.05096698e-03 -4.28996235e-03 ... -4.17764438e-03\n",
      "    -4.30802256e-03 -6.90575762e-05]\n",
      "   [-6.43548416e-03 -4.16394323e-03 -4.53535188e-03 ... -4.68625873e-03\n",
      "    -4.37358208e-03  1.33916023e-04]\n",
      "   ...\n",
      "   [-6.14779489e-03 -4.17199451e-03 -4.12868755e-03 ... -4.11138544e-03\n",
      "    -3.49153206e-03  2.03876101e-04]\n",
      "   [-5.46118012e-03 -3.93041270e-03 -3.67938401e-03 ... -3.56514822e-03\n",
      "    -3.08740884e-03  4.02582926e-04]\n",
      "   [-3.27647454e-03 -2.12497846e-03 -1.43123732e-03 ... -1.60587695e-03\n",
      "    -1.50453037e-04  2.03067623e-03]]\n",
      "\n",
      "  [[-1.79876387e-03 -3.07843229e-03 -2.76406342e-03 ... -2.36281753e-03\n",
      "    -2.50654551e-03 -1.12260714e-04]\n",
      "   [-2.94301950e-04 -8.19804147e-04 -6.19313738e-04 ... -8.39802611e-04\n",
      "    -5.12642320e-04 -2.97139370e-04]\n",
      "   [ 3.78639816e-04 -2.73079204e-04  3.87289649e-04 ...  4.23942547e-04\n",
      "     3.87482112e-04  5.74774458e-04]\n",
      "   ...\n",
      "   [ 5.09924372e-04 -3.47819150e-04 -1.62009193e-04 ... -3.56511853e-04\n",
      "     8.04861411e-05  3.41760227e-04]\n",
      "   [ 1.54058798e-04 -2.57047126e-04  1.64270623e-05 ... -6.12759322e-04\n",
      "    -4.09313332e-04 -2.95389182e-04]\n",
      "   [-6.50232076e-04 -2.05917284e-04  5.27257333e-04 ...  6.94048184e-04\n",
      "     1.64582918e-04  1.10650703e-03]]\n",
      "\n",
      "  [[ 1.24437443e-03  6.58102392e-04  9.68392473e-04 ...  1.31385552e-03\n",
      "     8.75292870e-04  7.35872309e-04]\n",
      "   [ 2.04698509e-03  1.06894644e-03  1.44250423e-03 ...  1.89867464e-03\n",
      "     7.12346518e-04  8.79385043e-04]\n",
      "   [ 2.30379449e-03  1.65181840e-03  1.81973341e-03 ...  2.18147016e-03\n",
      "     1.22797606e-03  8.56326544e-04]\n",
      "   ...\n",
      "   [ 2.20608455e-03  1.85388478e-03  2.07663071e-03 ...  1.93095871e-03\n",
      "     1.43802876e-03  9.79096978e-04]\n",
      "   [ 1.93897646e-03  1.18226977e-03  1.77355495e-03 ...  1.40290253e-03\n",
      "     1.16686348e-03  1.08321030e-04]\n",
      "   [ 2.51204870e-03  2.07514851e-03  1.56831543e-03 ...  1.43798825e-03\n",
      "     1.17134093e-03  7.38633913e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-7.88422767e-04 -2.08403682e-03 -1.72889372e-03 ... -1.43108261e-03\n",
      "    -1.00260112e-03 -2.66246125e-03]\n",
      "   [-1.42785267e-03 -1.74738048e-03 -1.90990698e-03 ... -1.78321730e-03\n",
      "    -1.11042312e-03 -1.11318904e-03]\n",
      "   [-1.77326682e-03 -2.47735600e-03 -2.58478080e-03 ... -2.42714118e-03\n",
      "    -1.66318624e-03 -1.22612552e-03]\n",
      "   ...\n",
      "   [-1.45430758e-03 -2.26975465e-03 -2.35402700e-03 ... -2.22574919e-03\n",
      "    -1.18670368e-03 -1.47651392e-03]\n",
      "   [-6.95565715e-04 -1.34048332e-03 -1.79845560e-03 ... -1.11776858e-03\n",
      "    -1.42571493e-03 -1.65715348e-03]\n",
      "   [ 1.81841780e-03  1.41251110e-03  1.27502554e-03 ...  1.11690245e-03\n",
      "     1.10968412e-03  1.50583265e-03]]\n",
      "\n",
      "  [[-2.43620900e-03 -2.35877535e-03 -2.87181512e-03 ... -2.78008054e-03\n",
      "    -2.20337231e-03 -2.55351746e-03]\n",
      "   [-1.65614684e-03 -6.07069640e-04 -9.78773343e-04 ... -8.36291234e-04\n",
      "    -3.62375256e-04 -1.02744042e-03]\n",
      "   [-1.52905146e-03 -4.82109288e-04 -1.06944074e-03 ... -1.15929346e-03\n",
      "    -5.92325057e-04 -9.93240508e-04]\n",
      "   ...\n",
      "   [-1.72379159e-03 -3.96007817e-04 -1.35888217e-03 ... -1.39809132e-03\n",
      "    -4.60331154e-04 -1.51979842e-03]\n",
      "   [-8.25584633e-04  8.17288470e-04 -2.69622280e-04 ... -4.86424193e-04\n",
      "     2.08056372e-04 -5.77251543e-04]\n",
      "   [ 9.78604308e-04  2.26895767e-03  1.24095660e-03 ...  1.26685644e-03\n",
      "     7.43047043e-04 -6.46544504e-04]]\n",
      "\n",
      "  [[-1.70314452e-03 -2.41343002e-03 -2.08672159e-03 ... -2.37191305e-03\n",
      "    -2.31514103e-03 -4.09781758e-04]\n",
      "   [-1.46028085e-03 -7.99504778e-05 -1.03697166e-04 ... -2.26639095e-04\n",
      "     2.75468861e-04  2.06003105e-03]\n",
      "   [-1.63498125e-03  1.32969918e-03 -1.38056803e-05 ...  3.31203191e-04\n",
      "     6.53232506e-04  2.62550055e-03]\n",
      "   ...\n",
      "   [-1.51162664e-03  1.15331984e-03  4.59820876e-04 ...  7.26673286e-04\n",
      "     5.10179496e-04  2.71702302e-03]\n",
      "   [-3.82715225e-04  1.79966295e-03  1.64101075e-03 ...  1.31464412e-03\n",
      "     1.21592951e-03  2.81831133e-03]\n",
      "   [ 7.87501689e-04  4.68304893e-03  4.53505618e-03 ...  4.11803462e-03\n",
      "     3.92167130e-03  3.15842452e-03]]]]\n",
      "<NDArray 1x512x32x32 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "go_forward(vgg_16())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把通道数换到最后\n",
    "def flatten_pred(pred):\n",
    "    return pred.transpose((0,2,3,1)).flatten()\n",
    "\n",
    "def concat_pred(preds):\n",
    "    return nd.concat(*[flatten_pred(pred) for pred in preds],dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义SSD中前向运算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_forward(net,X,sizes,ratios,cls_predictor,bbox_predictor):\n",
    "    #首先计算这一层的输出\n",
    "    Y = net(X)\n",
    "    #生成默认锚框\n",
    "    anchors = contrib.nd.MultiBoxPrior(Y,sizes=sizes,ratios=ratios)\n",
    "    #进行预测\n",
    "    cls_preds = cls_predictor(Y)\n",
    "    bbox_preds = bbox_predictor(Y)\n",
    "    #输出生成的默认锚框，类别预测，偏移量预测\n",
    "    return (Y,anchors,cls_preds,bbox_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blk(i):\n",
    "    if i==0:\n",
    "        return vgg_16()\n",
    "    elif i==4:\n",
    "        return nn.GlobalMaxPool2D()\n",
    "    else:\n",
    "        return down_sample_blk(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD(nn.Block):\n",
    "    def __init__(self,num_classes,**kwargs):\n",
    "        super(SSD,self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes           #需要预测的总类别数\n",
    "        self.sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79],\n",
    "                      [0.88, 0.961]]\n",
    "        self.ratios = [[0.35, 1.5, 0.75]] * 5                      #超参数，每一层我们需要生成的锚框宽高比和大小比例\n",
    "        #下面定义每一层的网络\n",
    "        for i in range(5):\n",
    "            #这一层的每个像素的锚框个数\n",
    "            num_anchors = len(self.sizes[i])+len(self.ratios[i])-1\n",
    "            #卷积层\n",
    "            setattr(self,'blk_%d' % i,get_blk(i))\n",
    "            #类别预测\n",
    "            setattr(self,'cls_pred_%d' % i,cls_predictor(num_anchors,num_classes))\n",
    "            #锚框偏移量预测\n",
    "            setattr(self,'bbox_pred_%d' % i ,bbox_predictor(num_anchors))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        #前向运算函数\n",
    "        anchors,cls_preds,bbox_preds= [],[],[]\n",
    "        \n",
    "        for i in range(5):\n",
    "            #进行一次前向运算\n",
    "            X,anchor,cls_pred,bbox_pred = blk_forward(getattr(self,'blk_%d' % i),X,self.sizes[i],self.ratios[i],\n",
    "                                                     getattr(self,'cls_pred_%d' % i),\n",
    "                                                     getattr(self,'bbox_pred_%d' % i))\n",
    "            #将输出追加到结果中\n",
    "            anchors.append(anchor)\n",
    "            cls_preds.append(cls_pred)\n",
    "            bbox_preds.append(bbox_pred)\n",
    "        #最后将结果输出\n",
    "        return(nd.concat(*anchors,dim=1),\n",
    "               concat_pred(cls_preds).reshape((0,-1,self.num_classes+1)),\n",
    "               concat_pred(bbox_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_ssd = SSD(num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class smooth_L1Loss(gloss.Loss):\n",
    "    def __init__(self,sigma=0.5,weight=None,batch_axis=0,data_axis=-1,**kwargs):\n",
    "        super(smooth_L1Loss,self).__init__(weight,batch_axis,**kwargs)\n",
    "        self.axis = data_axis\n",
    "        self._sigma = sigma\n",
    "       \n",
    "    #loss里面有很多函数可以自己来定义loss\n",
    "    def hybrid_forward(self,F,pred,label,sample_weight=None): \n",
    "        loss = F.smooth_l1((pred-label),scalar=self._sigma)\n",
    "        loss = gluon.loss._apply_weighting(F,loss,self._weight,sample_weight)\n",
    "        return F.mean(loss,axis = self._batch_axis,exclude =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class focal_SoftMaxCrossEntropy(gloss.Loss):\n",
    "    def __init__(self,gamma=2.0,data_axis=-1,batch_axis=0,\n",
    "                sparse_label = True,from_logits = False,eps =1e-5,weight=None,**kwargs):\n",
    "        super(focal_SoftMaxCrossEntropy,self).__init__(weight,batch_axis,**kwargs)\n",
    "        self._gamma = 2.0\n",
    "        self._axis = data_axis\n",
    "        self._sparse_label = sparse_label\n",
    "        self._from_logits = from_logits\n",
    "        self._eps = eps\n",
    "    \n",
    "    def hybrid_forward(self,F,pred,label,smaple_weight = None):\n",
    "        if not self._from_logits:\n",
    "            #计算一次softmax\n",
    "            pred = F.softmax(pred,axis = self._axis)\n",
    "        if self._sparse_label:\n",
    "            #这里keep_dim是为了后面与 smaple_weight相乘\n",
    "            pred = nd.pick(pred,label,axis=self._axis,keepdims=True)\n",
    "            loss = -((1-pred)**self._gamma)*F.log(pred+self._eps)\n",
    "        loss  = gluon.loss._apply_weighting(F,loss,self._weight,smaple_weight)\n",
    "        return F.mean(loss,axis = self._batch_axis,exclude=True)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpu(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_SSD = SSD(num_classes=1)\n",
    "ctx = gb.try_gpu()\n",
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_SSD.initialize(init = init.Xavier(),ctx=ctx)\n",
    "trainer = gluon.Trainer(tiny_SSD.collect_params(),'sgd',{'learning_rate':0.2,'wd':5e-4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义评价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_eval(cls_pred,cls_label):\n",
    "    return (cls_pred.argmax(axis=-1)==cls_label).mean().asscalar()\n",
    "\n",
    "def bbox_eval(bbox_pred,bbox_label,bbox_mask):\n",
    "    return (bbox_pred*bbox_mask-bbox_label*bbox_mask).abs().mean().asscalar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_L1 = smooth_L1Loss()\n",
    "focal_loss = focal_SoftMaxCrossEntropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_iter,test_iter =gb.load_data_pikachu(batch_size)\n",
    "train_iter.reshape(label_shape=(3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoches = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[109. 106. 106. ... 135. 136. 135.]\n",
       "   [109. 106. 106. ... 136. 136. 136.]\n",
       "   [108. 106. 105. ... 136. 136. 137.]\n",
       "   ...\n",
       "   [ 79.  56.  74. ... 128. 127. 131.]\n",
       "   [ 95.  98.  99. ... 139. 139. 135.]\n",
       "   [125. 121. 140. ... 126. 127. 131.]]\n",
       "\n",
       "  [[ 98.  95.  95. ... 126. 127. 126.]\n",
       "   [ 98.  95.  95. ... 128. 128. 128.]\n",
       "   [ 97.  95.  94. ... 128. 128. 129.]\n",
       "   ...\n",
       "   [ 72.  49.  67. ...  76.  75.  79.]\n",
       "   [ 88.  91.  92. ...  83.  83.  79.]\n",
       "   [121. 117. 136. ...  78.  79.  81.]]\n",
       "\n",
       "  [[ 80.  77.  77. ... 109. 110. 109.]\n",
       "   [ 80.  77.  77. ... 109. 109. 109.]\n",
       "   [ 79.  77.  76. ... 109. 109. 110.]\n",
       "   ...\n",
       "   [ 67.  44.  62. ...  43.  41.  45.]\n",
       "   [ 80.  83.  84. ...  46.  45.  41.]\n",
       "   [119. 115. 134. ...  35.  36.  38.]]]\n",
       "\n",
       "\n",
       " [[[119. 120. 120. ... 169. 132. 127.]\n",
       "   [119. 120. 122. ... 172. 164. 156.]\n",
       "   [119. 120. 122. ... 167. 158. 161.]\n",
       "   ...\n",
       "   [ 58.  58.  50. ...  72.  66.  64.]\n",
       "   [ 56.  69.  66. ...  71.  65.  64.]\n",
       "   [ 62.  78.  84. ...  71.  67.  68.]]\n",
       "\n",
       "  [[200. 199. 198. ... 136. 113. 122.]\n",
       "   [200. 199. 200. ... 136. 141. 140.]\n",
       "   [200. 199. 200. ... 142. 140. 141.]\n",
       "   ...\n",
       "   [ 54.  57.  57. ...  67.  61.  59.]\n",
       "   [ 52.  68.  69. ...  65.  58.  58.]\n",
       "   [ 59.  75.  77. ...  63.  59.  60.]]\n",
       "\n",
       "  [[247. 247. 246. ... 139. 126. 143.]\n",
       "   [247. 247. 248. ... 132. 145. 152.]\n",
       "   [247. 247. 248. ... 138. 145. 151.]\n",
       "   ...\n",
       "   [ 27.  41.   3. ...  64.  58.  56.]\n",
       "   [ 22.  42.  14. ...  62.  55.  55.]\n",
       "   [ 23.  39.  27. ...  60.  56.  57.]]]\n",
       "\n",
       "\n",
       " [[[  9.  12.   9. ...  26.  30.  18.]\n",
       "   [  7.  13.   9. ...  20.  24.  15.]\n",
       "   [  6.  10.   8. ...  16.  26.  16.]\n",
       "   ...\n",
       "   [ 12.  10.   9. ...  83.  84.  84.]\n",
       "   [ 12.   9.   9. ...  92.  90.  90.]\n",
       "   [ 13.  10.   8. ... 113. 107. 102.]]\n",
       "\n",
       "  [[  4.   7.   4. ...   7.  12.   2.]\n",
       "   [  3.   8.   4. ...   6.   9.   1.]\n",
       "   [  2.   5.   3. ...   8.  16.   2.]\n",
       "   ...\n",
       "   [ 14.  11.  10. ...  64.  65.  68.]\n",
       "   [ 14.  10.   9. ...  70.  68.  69.]\n",
       "   [ 17.  13.  11. ...  85.  80.  74.]]\n",
       "\n",
       "  [[  1.   4.   0. ...   0.   6.   0.]\n",
       "   [  0.   5.   0. ...   4.   6.   0.]\n",
       "   [  0.   2.   0. ...   5.  12.   1.]\n",
       "   ...\n",
       "   [  3.   3.   2. ...  60.  58.  57.]\n",
       "   [  3.   3.   2. ...  61.  61.  59.]\n",
       "   [  3.   2.   1. ...  66.  62.  58.]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[180. 180. 180. ... 204. 199. 193.]\n",
       "   [186. 184. 184. ... 212. 212. 209.]\n",
       "   [189. 189. 188. ... 212. 210. 212.]\n",
       "   ...\n",
       "   [150. 146. 143. ...  45.  44.  44.]\n",
       "   [142. 139. 139. ...  46.  43.  44.]\n",
       "   [141. 139. 138. ...  46.  44.  43.]]\n",
       "\n",
       "  [[187. 188. 188. ... 206. 200. 194.]\n",
       "   [190. 189. 189. ... 211. 212. 208.]\n",
       "   [194. 194. 193. ... 211. 210. 212.]\n",
       "   ...\n",
       "   [172. 167. 167. ...  49.  51.  53.]\n",
       "   [165. 162. 162. ...  53.  52.  53.]\n",
       "   [164. 162. 161. ...  53.  52.  52.]]\n",
       "\n",
       "  [[192. 191. 191. ... 205. 203. 199.]\n",
       "   [193. 192. 192. ... 207. 211. 208.]\n",
       "   [198. 197. 196. ... 207. 209. 212.]\n",
       "   ...\n",
       "   [152. 148. 147. ...  34.  35.  36.]\n",
       "   [145. 142. 142. ...  37.  35.  36.]\n",
       "   [144. 142. 141. ...  37.  36.  35.]]]\n",
       "\n",
       "\n",
       " [[[130. 128. 128. ...  83.  84.  86.]\n",
       "   [131. 130. 128. ...  84.  85.  87.]\n",
       "   [132. 134. 133. ...  84.  85.  87.]\n",
       "   ...\n",
       "   [ 90.  89.  90. ... 129. 127. 126.]\n",
       "   [ 89.  89.  88. ... 131. 126. 126.]\n",
       "   [ 91.  91.  90. ... 127. 127. 128.]]\n",
       "\n",
       "  [[171. 170. 170. ... 100. 101. 101.]\n",
       "   [171. 172. 171. ... 101. 102. 102.]\n",
       "   [171. 174. 173. ... 101. 102. 102.]\n",
       "   ...\n",
       "   [ 93.  92.  93. ... 133. 131. 130.]\n",
       "   [ 92.  92.  91. ... 135. 130. 130.]\n",
       "   [ 92.  93.  91. ... 131. 131. 132.]]\n",
       "\n",
       "  [[196. 195. 195. ... 110. 111. 112.]\n",
       "   [196. 197. 196. ... 111. 112. 113.]\n",
       "   [195. 199. 199. ... 111. 112. 113.]\n",
       "   ...\n",
       "   [ 98.  97.  98. ... 136. 134. 131.]\n",
       "   [ 97.  97.  96. ... 138. 133. 131.]\n",
       "   [ 97.  98.  96. ... 134. 134. 132.]]]\n",
       "\n",
       "\n",
       " [[[160. 198. 171. ... 100.  97.  96.]\n",
       "   [151. 191. 181. ...  99.  98.  97.]\n",
       "   [146. 187. 180. ...  99.  99.  98.]\n",
       "   ...\n",
       "   [143. 142. 140. ... 157. 155. 151.]\n",
       "   [139. 138. 135. ... 162. 157. 155.]\n",
       "   [134. 133. 131. ... 163. 160. 155.]]\n",
       "\n",
       "  [[138. 174. 151. ... 130. 130. 131.]\n",
       "   [129. 166. 160. ... 129. 131. 132.]\n",
       "   [122. 160. 159. ... 129. 132. 133.]\n",
       "   ...\n",
       "   [119. 118. 115. ... 135. 135. 131.]\n",
       "   [116. 116. 113. ... 137. 135. 132.]\n",
       "   [112. 111. 110. ... 139. 136. 132.]]\n",
       "\n",
       "  [[127. 165. 128. ... 200. 199. 199.]\n",
       "   [116. 155. 137. ... 199. 200. 200.]\n",
       "   [110. 149. 137. ... 199. 201. 201.]\n",
       "   ...\n",
       "   [ 94.  93.  88. ... 103. 102.  98.]\n",
       "   [ 93.  93.  86. ... 103. 101. 100.]\n",
       "   [ 89.  88.  83. ... 105. 102.  98.]]]]\n",
       "<NDArray 32x3x256x256 @cpu(0)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter.next().data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epoches):\n",
    "    for epoch in range(num_epoches):\n",
    "        start = time.time()\n",
    "        train_cls_acc = 0\n",
    "        train_bbox_loss = 0\n",
    "        train_iter.reset()\n",
    "\n",
    "        for i,batch in enumerate(train_iter):\n",
    "            #获取小批量数据\n",
    "            X = batch.data[0].as_in_context(ctx)\n",
    "            Y = batch.label[0].as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                #前向运算\n",
    "                anchors,cls_preds,bbox_preds = tiny_SSD(X)\n",
    "                #标记锚框获得标签,这里还可以设置负采样\n",
    "                bbox_labels,bbox_masks,cls_labels= contrib.nd.MultiBoxTarget(anchors,Y,cls_preds.transpose((0,2,1)))\n",
    "                #计算损失\n",
    "                l_cls = focal_loss(cls_preds,cls_labels)\n",
    "                l_bbox = smooth_L1(bbox_preds*bbox_masks,bbox_labels*bbox_masks)\n",
    "                l_total = l_cls+l_bbox\n",
    "            #反向传播\n",
    "            l_total.backward()\n",
    "            #迭代参数\n",
    "            trainer.step(batch_size)\n",
    "            train_cls_acc += cls_eval(cls_preds,cls_labels)\n",
    "            train_bbox_loss += bbox_eval(bbox_preds,bbox_labels,bbox_masks)\n",
    "        #训练完epoch输出结果\n",
    "        print('epoch %2d , train_cls_acc %.2f , bbox mae %.2e , time %.1f sec' %\n",
    "             (epoch+1,train_cls_acc/(i+1),train_bbox_loss/(i+1),time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
