{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用mxnet的gluon接口来实现多层感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx \n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mxnet import gluon,nd,autograd\n",
    "from mxnet.gluon import data as gdata,loss as gloss,nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 首先还是准备小批量数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToTensor(data,label):\n",
    "    return data.astype(np.float32)/255,label.astype(np.float32)\n",
    "ctx = mx.gpu()\n",
    "\n",
    "batch_size = 256\n",
    "with mx.Context(ctx):\n",
    "    trainData = gdata.vision.FashionMNIST(root=\"./FashionMNIST\",train = True,transform=ToTensor)\n",
    "    testData = gdata.vision.FashionMNIST(root=\"./FashionMNIST\",train = False,transform=ToTensor)\n",
    "    \n",
    "    train_iter = gdata.DataLoader(trainData,batch_size,shuffle=True)\n",
    "    test_iter = gdata.DataLoader(testData,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[9. 0. 5. 8. 7. 9. 3. 2. 2. 8. 8. 0. 6. 8. 0. 5. 9. 9. 2. 4. 2. 9. 8. 5.\n",
      " 5. 8. 0. 4. 6. 5. 3. 7. 1. 9. 0. 4. 2. 5. 4. 6. 1. 1. 1. 9. 6. 9. 9. 1.\n",
      " 4. 8. 9. 7. 7. 9. 2. 4. 0. 0. 4. 0. 4. 8. 1. 6. 2. 1. 0. 7. 6. 8. 4. 1.\n",
      " 3. 5. 3. 8. 4. 1. 3. 9. 4. 2. 1. 5. 3. 7. 3. 1. 3. 7. 7. 3. 3. 0. 7. 4.\n",
      " 7. 8. 0. 5. 5. 2. 3. 2. 1. 2. 2. 2. 3. 1. 2. 7. 6. 0. 4. 6. 0. 5. 5. 5.\n",
      " 4. 0. 2. 5. 5. 3. 9. 3. 0. 3. 4. 3. 9. 0. 3. 4. 3. 5. 0. 4. 9. 8. 8. 9.\n",
      " 2. 5. 6. 1. 2. 8. 9. 6. 4. 7. 5. 8. 3. 0. 2. 6. 8. 5. 3. 2. 5. 8. 9. 9.\n",
      " 1. 5. 4. 0. 6. 8. 9. 8. 8. 7. 8. 6. 2. 8. 2. 1. 3. 1. 5. 1. 3. 9. 9. 4.\n",
      " 9. 6. 3. 8. 4. 4. 4. 3. 0. 8. 3. 3. 6. 0. 7. 9. 2. 8. 8. 4. 4. 7. 7. 9.\n",
      " 0. 8. 8. 2. 4. 8. 9. 4. 8. 1. 8. 4. 7. 5. 5. 9. 7. 5. 6. 5. 8. 9. 3. 6.\n",
      " 2. 3. 4. 0. 9. 5. 2. 9. 2. 6. 5. 5. 5. 0. 4. 1.]\n",
      "<NDArray 256 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for X,y in train_iter:\n",
    "    break\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用gluon搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "\n",
    "net = nn.Sequential()  #定义一个容器\n",
    "net.add(nn.Dense(1000,activation='relu'),\n",
    "       nn.Dense(10))                      #为模型中添加层\n",
    "net.initialize(init.Normal(sigma=0.01),ctx=ctx)   #初始化模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gloss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat,y):\n",
    "    return (y_hat.argmax(axis = 1)==y).mean().asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net,datas):\n",
    "    acc = 0\n",
    "    for X,y in datas:\n",
    "        acc+=accuracy(net(X),y)\n",
    "    return acc/len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1787109375\n"
     ]
    }
   ],
   "source": [
    "with mx.Context(ctx):\n",
    "    print(evaluate_accuracy(net,test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(net,train_iter,test_iter,num_epochs,batch_size,loss,trainer):\n",
    "    for epoch in range(0,num_epochs+1):\n",
    "        train_l_sum = 0\n",
    "        train_acc_sum = 0\n",
    "        \n",
    "        for X,y in train_iter:\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat,y)\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            \n",
    "            train_l_sum += l.mean().asscalar()\n",
    "            train_acc_sum += accuracy(y_hat,y)\n",
    "        \n",
    "        test_acc = evaluate_accuracy(net,test_iter)\n",
    "        \n",
    "        print('epoch %d train_loss %.4f train_acc %.3f test_acc %.3f'\n",
    "             %(epoch+1,train_l_sum/len(train_iter),train_acc_sum/len(train_iter),test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train_loss 0.4780 train_acc 0.834 test_acc 0.836\n",
      "epoch 2 train_loss 0.4690 train_acc 0.835 test_acc 0.843\n",
      "epoch 3 train_loss 0.4521 train_acc 0.843 test_acc 0.847\n",
      "epoch 4 train_loss 0.4455 train_acc 0.846 test_acc 0.854\n",
      "epoch 5 train_loss 0.4352 train_acc 0.849 test_acc 0.855\n",
      "epoch 6 train_loss 0.4266 train_acc 0.852 test_acc 0.857\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "with mx.Context(ctx):\n",
    "    train_mlp(net,train_iter,test_iter,num_epochs,batch_size,loss,trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
